# -*- coding: utf-8 -*-
"""project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1doEy9XJRi55VQLmuRjUuCe9pKSZ63BtH

‚úÖ ***Step 1 ‚Äì Problem Definition (Detailed)***

üéØ1Ô∏è‚É£ Objective of the Project
‚úÖDesign an Artificial Intelligence (Machine Learning) system that can:

‚úÖPredict if a student is likely to drop out of school

‚úÖIdentify and explain the key reasons behind the dropout risk

‚úÖHelp school administrators take action based on the prediction and

‚úÖexplanation

‚úçÔ∏è 2Ô∏è‚É£ Define Inputs and Outputs

‚ñ∂Ô∏è Inputs (Features):

Feature Name	Description

Age	Age of the student

Gender	Male / Female

Parent‚Äôs Education	Highest education of parent

Socio-Economic Status	Low / Medium / High

Attendance Rate	Percentage of attendance

Academic Grades	Average marks in previous years

Family Support	Yes / No

Distance from School	In kilometers

Study Hours	Daily average study time in hours

Dropout Label	Target variable: Yes / No (binary classification)

‚úÖ 3Ô∏è‚É£ Define Success Criteria

Model accuracy ‚â• 80%

Clear explanation of dropout reasons based on feature importance

A basic interface (report or dashboard) that shows predictions and key reasons

Data preprocessing handles missing values and noisy data effectively

System is repeatable and works on unseen data

‚úÖ 4Ô∏è‚É£ Scope Definition (What Is In/Out of Scope)

‚úîÔ∏è In Scope:

Structured dataset (tabular)

Classification model (Decision Tree / Logistic Regression)

Feature importance explanation

Basic report generation

‚ùå Out of Scope:

Complex deep learning models (for now)

Complex multi-language support

Real-time system (unless deployment is added later)

‚úÖ 5Ô∏è‚É£ Final Problem Statement

üëâ ‚ÄúDesign a Machine Learning-based system that predicts whether a student will drop out of school based on demographic, academic, and socio-economic factors, and explains the top reasons for potential dropout using interpretable models like Decision Trees.‚Äù

***‚úÖ Step 2 ‚Äì Load the Dataset in Google Colab***

‚úÖ***Uploading the dataset***
"""

import pandas as pd

# Load uploaded dataset (assume the file is uploaded directly)
df = pd.read_csv('/content/student_dropout.csv')

# Show first few rows
df.head()

"""***‚úÖOnce the dataset is loaded, we will:
‚úîÔ∏è Inspect missing values
‚úîÔ∏è Check data types of each column
‚úîÔ∏è See basic statistics (mean, min, max, etc.)
‚úîÔ∏è Check class balance in the target (dropout rate)***
"""

# Check dataset info
df.info()

# Check for missing values
df.isnull().sum()

# Statistics summary
df.describe()

# Class balance in target variable
df['dropout'].value_counts()

"""***‚úÖ Step 3 ‚Äì Data Preprocessing in Google Colab***

**‚úÖ 1Ô∏è‚É£ Inspect Missing Values and Data Types**
"""

# Check missing values
print(df.isnull().sum())

# Check data types
print(df.dtypes)

"""‚úÖ**2Ô∏è‚É£ Handle Missing Values
üëâ Example strategies:
Drop rows with too many missing values
Impute missing values (for numerical columns, use mean/median; for categorical columns, use mode)**
"""

# Fill missing numerical values with mean
numerical_cols = ['age', 'attendance_rate', 'grades_avg', 'distance_school_km', 'study_hours']
df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].mean())

# Fill missing categorical values with mode
categorical_cols = ['gender', 'parent_education', 'socio_economic_status', 'family_support']
for col in categorical_cols:
    df[col] = df[col].fillna(df[col].mode()[0])

"""‚úÖ**3Ô∏è‚É£ Encode Categorical Variables
üëâ ML models require numeric data, so we encode categorical features:**
"""

from sklearn.preprocessing import LabelEncoder

label_encoders = {}
for col in categorical_cols:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le  # Save the encoder for later use

"""‚úÖ**4Ô∏è‚É£Normalize Numerical Features (Optional but Recommended)
üëâ Helps improve model performance**
"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
df[numerical_cols] = scaler.fit_transform(df[numerical_cols])

"""‚úÖ**5Ô∏è‚É£ Split Dataset into Training and Test Sets**"""

from sklearn.model_selection import train_test_split

X = df.drop(columns=['student_id', 'dropout'])  # Features
y = df['dropout']  # Target variable

# Train-test split (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f'Training samples: {X_train.shape[0]}')
print(f'Test samples: {X_test.shape[0]}')

"""‚úÖ**6Ô∏è‚É£ **Final** Prepared Dataset Summary
At this point, the dataset is ready for model training:
No missing values
All categorical variables encoded as numbers
Numerical features scaled
Proper train-test split created**

***üß† Step 4 ‚Äì Model Selection and Training***

‚úÖ **1Ô∏è‚É£ Select Simple and Interpretable Model
We will start with a Decision Tree Classifier because:
Easy to implement
Provides feature importance
High interpretability**

‚úÖ **2Ô∏è‚É£ Train the Decision Tree Model**
"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Initialize the Decision Tree Classifier
model = DecisionTreeClassifier(random_state=42)

# Train the model
model.fit(X_train, y_train)

"""‚úÖ **3Ô∏è‚É£ Evaluate Model Performance**"""

# Predict on test set
y_pred = model.predict(X_test)

# Accuracy score
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')

# Classification report
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Confusion matrix
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))

"""‚úÖ **4Ô∏è‚É£ Extract Feature Importance for Explanation**"""

import matplotlib.pyplot as plt
import pandas as pd

# Get feature importances
feature_importance = model.feature_importances_

# Create a DataFrame for visualization
features = X_train.columns
importance_df = pd.DataFrame({
    'Feature': features,
    'Importance': feature_importance
}).sort_values(by='Importance', ascending=False)

# Plot feature importance
plt.figure(figsize=(10, 6))
plt.barh(importance_df['Feature'], importance_df['Importance'])
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.title('Feature Importance in Predicting Dropout')
plt.gca().invert_yaxis()
plt.show()

"""‚úÖ **5Ô∏è‚É£ Conclusion of Step-4
After completing this step, we will have:
A trained and evaluated Decision Tree model
Accuracy, precision, recall metrics
Feature importance that explains why the model predicts dropout risk**

‚úÖ ***Step 5 ‚Äì Create a Simple Report / Dashboard***

Our goal:

‚ñ∂Ô∏è Allow the school administrator to input student data, get a prediction, and view the top reasons why a student is at risk of dropping out.

‚úÖ**1Ô∏è‚É£ Define Input Example (Single Student Data):**
"""

# Example single student input (should be a DataFrame with same columns as X_train)
sample_student = pd.DataFrame({
    'age': [0.1],  # Scaled value
    'gender': [1],  # Encoded
    'parent_education': [2],  # Encoded
    'socio_economic_status': [1],  # Encoded
    'attendance_rate': [-1.0],  # Scaled
    'grades_avg': [-0.5],  # Scaled
    'family_support': [1],  # Encoded
    'distance_school_km': [0.3],  # Scaled
    'study_hours': [-0.2]  # Scaled
})

"""‚úÖ **2Ô∏è‚É£ Make Dropout Prediction and Probability**"""

# Predict class (0 or 1)
predicted_class = model.predict(sample_student)[0]

# Predict probability of dropout
predicted_prob = model.predict_proba(sample_student)[0][1]

print(f"Predicted Dropout Class: {'Yes' if predicted_class == 1 else 'No'}")
print(f"Dropout Probability: {predicted_prob * 100:.2f}%")

"""‚úÖ **3Ô∏è‚É£ Explain Top Reasons (Feature Importance)**"""

# Extract overall feature importance
feature_importance = model.feature_importances_

# Create a DataFrame
importance_df = pd.DataFrame({
    'Feature': X_train.columns,
    'Importance': feature_importance
}).sort_values(by='Importance', ascending=False)

# Show top 3 reasons
top_reasons = importance_df.head(3)
print("\nTop 3 Features Contributing to Dropout Risk:")
print(top_reasons)

"""‚úÖ **4Ô∏è‚É£ Putting It All Together ‚Äì Sample Output**"""

